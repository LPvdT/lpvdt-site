{
	"personal_info": {
		"name": "Laurens van der Tas",
		"title": "Senior Cloud Data Platform & MLOps Engineer",
		"location": "Rotterdam, South Holland, Netherlands",
		"email": "laurens.vandertas@gmail.com",
		"website": "https://lpvdt.github.io",
		"linkedin": "https://linkedin.com/in/lpvdt",
		"github": "https://github.com/LPvdT"
	},
	"profile": "Senior Data Platform & MLOps Engineer with a track record of building data systems from the ground up and guiding them into fully automated, production-grade platforms. My career began at the intersection of econometrics and software engineering as a freelance developer, progressed into data science and advanced analytics, and has since evolved into leading machine learning and MLOps initiatives at scale. I bring a unique blend of engineering craftsmanship and quantitative expertise, backed by an MSc with a solid econometric background. Whether designing architectures, operationalizing ML, or mentoring teams, I focus on turning complex data problems into solutions that deliver long-term value. Academic excellence (both theses graded 9/10) underscores a commitment to precision, while open-source contributions and continuous learning reflect my drive to stay ahead in a rapidly changing field.",
	"experience": [
		{
			"title": "Senior Cloud Data Platform & MLOps Engineer",
			"company": "DELTA Fiber",
			"location": "Schiedam, Netherlands",
			"period": "Sep 2024 -- Present",
			"description": "Leading the design and implementation of enterprise-scale cloud-native data platforms and MLOps solutions. Driving digital transformation through automated, production-ready machine learning systems that deliver measurable business impact.",
			"technologies": [
				"Python",
				"Databricks",
				"MLflow",
				"Kubernetes",
				"Docker",
				"Terraform",
				"Azure",
				"Kafka",
				"Airflow"
			]
		},
		{
			"title": "Senior Machine Learning Engineer",
			"company": "DELTA Fiber",
			"location": "Schiedam, Netherlands",
			"period": "Nov 2021 -- Aug 2024",
			"description": "Owned end-to-end machine learning lifecycle from research to production deployment. Built scalable ML infrastructure and established best practices for model monitoring, versioning, and continuous integration.",
			"technologies": [
				"Python",
				"TensorFlow",
				"PyTorch",
				"MLflow",
				"Kubernetes",
				"Azure",
				"Databricks"
			]
		},
		{
			"title": "Data Scientist/Engineer",
			"company": "DELTA Fiber",
			"location": "Schiedam, Netherlands",
			"period": "Nov 2018 -- Oct 2021",
			"description": "Pioneered the company's data-driven transformation by building the foundational data infrastructure and implementing the first production ML pipelines. Established modern data engineering practices and CI/CD workflows.",
			"technologies": ["Python", "R", "SQL", "Azure", "Databricks", "Power BI", "Docker"]
		},
		{
			"title": "Freelance Developer",
			"company": "Private Clients",
			"location": "Apeldoorn, Netherlands",
			"period": "Sep 2012 -- Aug 2018",
			"description": "Delivered full-stack web applications and econometric modeling solutions for diverse clients. Specialized in translating complex mathematical concepts into practical software solutions.",
			"technologies": ["Python", "R", "JavaScript", "SQL", "Docker", "Linux"]
		},
		{
			"title": "Commercial Insurance Agent",
			"company": "Achmea",
			"location": "Apeldoorn, Netherlands",
			"period": "2010 -- 2011",
			"description": "Provided sales and advisory services for commercial insurance products, developing strong client relationship and communication skills.",
			"technologies": []
		}
	],
	"skills": {
		"programming": [
			{
				"name": "Python",
				"level": "expert"
			},
			{
				"name": "R",
				"level": "expert"
			},
			{
				"name": "Rust",
				"level": "advanced"
			},
			{
				"name": "Scala",
				"level": "advanced"
			},
			{
				"name": "Go",
				"level": "advanced"
			},
			{
				"name": "TypeScript",
				"level": "advanced"
			},
			{
				"name": "React",
				"level": "intermediate"
			},
			{
				"name": "Next.js",
				"level": "intermediate"
			},
			{
				"name": "NestJS",
				"level": "intermediate"
			},
			{
				"name": "Svelte",
				"level": "intermediate"
			},
			{
				"name": "FastAPI",
				"level": "expert"
			},
			{
				"name": "TensorFlow",
				"level": "expert"
			},
			{
				"name": "PyTorch",
				"level": "expert"
			}
		],
		"data_engineering": [
			{
				"name": "Databricks",
				"level": "expert"
			},
			{
				"name": "MLflow",
				"level": "expert"
			},
			{
				"name": "dbt",
				"level": "expert"
			},
			{
				"name": "Kafka",
				"level": "expert"
			},
			{
				"name": "Flink",
				"level": "advanced"
			},
			{
				"name": "PySpark",
				"level": "expert"
			},
			{
				"name": "Polars",
				"level": "advanced"
			},
			{
				"name": "Airflow",
				"level": "expert"
			},
			{
				"name": "Dagster",
				"level": "advanced"
			},
			{
				"name": "DuckDB",
				"level": "advanced"
			}
		],
		"cloud_devops": [
			{
				"name": "Kubernetes",
				"level": "expert"
			},
			{
				"name": "Docker",
				"level": "expert"
			},
			{
				"name": "Terraform",
				"level": "expert"
			},
			{
				"name": "Azure",
				"level": "expert"
			},
			{
				"name": "GitHub Actions",
				"level": "advanced"
			},
			{
				"name": "Azure Pipelines",
				"level": "advanced"
			},
			{
				"name": "Helm",
				"level": "intermediate"
			}
		],
		"analytics": [
			{
				"name": "Machine Learning",
				"level": "expert"
			},
			{
				"name": "Deep Learning",
				"level": "expert"
			},
			{
				"name": "LLMs",
				"level": "expert"
			},
			{
				"name": "MLOps",
				"level": "expert"
			},
			{
				"name": "Econometrics",
				"level": "expert"
			},
			{
				"name": "Time Series Analysis",
				"level": "advanced"
			},
			{
				"name": "Reinforcement Learning",
				"level": "intermediate"
			}
		],
		"tools": [
			{
				"name": "Power BI",
				"level": "expert"
			},
			{
				"name": "Grafana",
				"level": "expert"
			},
			{
				"name": "Tableau",
				"level": "expert"
			},
			{
				"name": "Plotly",
				"level": "advanced"
			},
			{
				"name": "Git",
				"level": "expert"
			},
			{
				"name": "SQL/NoSQL",
				"level": "expert"
			}
		]
	},
	"education": [
		{
			"degree": "MSc Banking & Finance",
			"institution": "Utrecht University",
			"location": "Utrecht, Netherlands",
			"period": "2016 -- 2018",
			"description": "Focus on quantitative finance, econometrics, and investment management. Thesis on machine learning"
		},
		{
			"degree": "BSc Economics & Business Economics",
			"institution": "Utrecht University",
			"location": "Utrecht, Netherlands",
			"period": "2012 -- 2015",
			"description": "Customized programme emphasizing econometrics, statistics, and finance. Thesis graded"
		},
		{
			"degree": "International Business and Management Studies",
			"institution": "Avans University of Applied Sciences",
			"location": "Breda, Netherlands",
			"period": "2011",
			"description": "Propaedeutic obtained"
		},
		{
			"degree": "Pre-University Education (VWO)",
			"institution": "Edison College",
			"location": "Apeldoorn, Netherlands",
			"period": "2004 -- 2010",
			"description": "Science"
		}
	],
	"certifications": [
		{
			"name": "Dagster & dbt",
			"issuer": "Dagster Labs",
			"year": "2024",
			"description": "{Dagster Essentials, Dagster & dbt integration"
		},
		{
			"name": "NestJS Fundamentals & Authentication",
			"issuer": "NestJS",
			"year": "2023",
			"description": ""
		},
		{
			"name": "Applied Data Science (R & Python)",
			"issuer": "DataCamp",
			"year": "2017",
			"description": "{ARIMA Modelling, Intermediate R & Python, Time Series with xts & zoo"
		}
	],
	"projects": [
		{
			"name": "MLOps Platform",
			"description": "Built comprehensive MLOps platform with automated model deployment, monitoring, and lifecycle management using Databricks, MLflow, and Kubernetes.",
			"technologies": ["Python", "Databricks", "MLflow", "Kubernetes", "Docker"],
			"link": "https://github.com/LPvdT"
		},
		{
			"name": "Real-time Data Platform",
			"description": "Designed and implemented real-time streaming data platform handling millions of events daily using Kafka, Flink, and modern data lakehouse architecture.",
			"technologies": ["Kafka", "Flink", "Python", "Terraform", "Azure"],
			"link": "https://github.com/LPvdT"
		}
	]
}
